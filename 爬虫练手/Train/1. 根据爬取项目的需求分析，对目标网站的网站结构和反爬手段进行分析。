1. 根据爬取项目的需求分析，对目标网站的网站结构和反爬手段进行分析。
2. 利用 request、Scrapy 等技术手段编写爬虫程序对内容进行爬取。
3. 对爬取到的数据进行清洗过滤，分表存储。
4. 利用 Numpy 对处理后的数据进行分析。
5. 利用 Django 框架编写Web后端程序。
6. 对代码进行优化和维护。


1.观察前端页面，为降低页面数据重复，便于后期维护，采用模板标签BLOCK, Extends完成页面继承对前端页面进行再次封装。
 2.分析页面，对用户信息、商品信息进行数据库的设计及字段的创建。
 3.创建视图接受用户的POST请求完成用户的注册，运用Ajax技术对用户名进行唯一性校验，对密码进行sha256＋salt处理存入mysql数据库，调用分布式调度模块celery完成用户的邮箱验证,为防止用户暴力请求，导入pillow模块添加图形验证码
 4.创建视图，显示登录页面，接受用户的密码输入并对存入数据库的正确密码进行比对，如果密码正确，则转到个人信息页面，错误则显示错误提示信息，成功登陆后把用户名存入Cookie向session中写入用户编号信息，用于后续功能中的判断
 5. 创建装修器，用在个人信息、收货地址的视图上，如果未登录则转到登录页，如果已经登录则正常访问请求的视图
 6. 创建中间件，记录来源地址，登录成功后，转到来源地址如果来源地址是注册、登录及相关地址，则不记录
 7. 在页面的顶部，显示当前登录状态,如果已经登录则显示用户名、如果未登录则显示登录、注册
 8. 创建视图，完成退出功能，即清除session数据
 9．创建视图，完成商品模块首页，列表页，详情页，等页面的添加，并定义上下文结构，将数据传递到相关模板，模板遍历数据，对列表页进行分页，排序控制
 10.导入富文本编辑器tinymce对商品信息进行页面渲染,展现所见即所得的饱满商品信息页面
 11.配置admin，方便开发人员后期对数据的维护
 12.导入haystack,whoosh,jieba对用户的的模糊查询进行中文分词，提高查询性能，提升用户体验
 13.在商品模块中将用户对商品的浏览记录存入cookie, 在用户模块中读取cookie中的商品信息展示在用户个人中心的最近浏览区域



 2017/3--2017/8项目名称:亚马逊刷单软件
项目职责：1.参与系统，数据库，项目工程目录搭建与设计
 2.采用adminer数据库管理工具管理刷单配置信息
 3.编写adminer后台接口返回json数据的参数配置信息给刷单系统
 4.采用phpredis数据库管理工具管理亚马逊买家数据及系统操作数据及反馈数据
 5.采用phpredis记录系统买家的登录信息及所接入VPN供应商的具体信息
 6.导入python中configparse模块完成对config文件的配置及操作
 7.编写工具类模块代码完成与redis数据库的对接及mysql数据管理器的设置参数读取
 8.运用selenium＋firefoxprofile进行业务主逻辑模块dzamzslm的数据爬取及刷单行为操作，完成Firefox的个性化设置
 9.导入python中loggging模块进行log日志编写
 10.编写启动文件，完成刷单软件各种功能的实现
 11.编写亚马逊刷单软件的开发文档及面对亚马逊平台进行的反刷单行为进行系统策略改变及系统代码升级
项目描述：为提升公司亚马逊平台产品排名 模拟正常用户进行商品购买，评论等一系列买家操作行为开发刷单管理系统


2016.05--2018.11北京良物珍品电子商务股份有限公司
python开发工程师 | 8001-10000元/月 
  行业类别：互联网/电子商务
工作内容：1.负责系统平台的日常维护，配合团队其他成员进行模块开发及整合
2.对已完成项目的迭代开发，功能拓展，完善开发文档
3.对互联网相关信息进行抓取，为公司数据分析提供支持
2015.05--2016.05 北京麦田房产经纪有限公司
python开发工程师 | 4001-6000元/月 
  行业类别：互联网/电子商务
工作内容：1.负责系统平台的日常维护
2.对完成项目的版本迭代，功能扩展
3.配合团队其他成员进行模块开发及整合

Whoosh

-----------------------------------------------------------------------------------------------------------------------------------
2016.07--2017.09项目名称:”鹰眼”数据采集平台
项目职责：1、django主要负责测试提取规则的可用性，开始暂停爬虫，导出抓取的数据（csv）格式，以及将提取规则保存进数据库。

2、爬虫块：主要负责下载，解析，入库的流程控制。利用python协程的高并发特性，可同时支持上百爬虫同时运行。利用微服务架构，可全面实现分布式部署，突破单个机器性能的不足，使得同时运行爬虫任务不在有数量限制。

3、数据库（核心）：因为采用的是微服务架构，django、爬虫模块与数据库交互都是通过数据库模块的API来实现。内部利用python协程的特性来实现高并发，并采用数据库连接池来减少频繁连接数据库。
项目描述：项目介绍：
“鹰眼”平台主要功能是：通过web界面提交提取抓取规则（正则，xpath、css），来实现抓取。
主要有三大部分：django、爬虫、数据库。
技术： (1):python ＋ 异步协程
   (2):微服务(爬虫稳定性增强)
       (3):docker(分布式集群部署，负载均衡，全面发挥每台服务器的性能)
优点： 
(1):python＋异步协程：
在遇见I/O操作的时候，程序会将控制权交出去，并记录这个位置。当操作执行完毕后，程序会继续在此位置向下执行，以此节约了大量的时间。
(2):微服务：
微服务架构，直接将爬虫完美的分为几个块，下载，解析，数据库交互。这几个模块独立运行，通过一个主流程控制进行解耦，使得爬虫的稳定性大大增加
(3):docker
在大量爬虫同时运行的时候，耗费机器性能的地方主要是下载和解析两大块。爬虫一旦大量运行，带宽，cpu消耗都是限制爬虫速度的瓶颈。而利用微服务将其写成API, 再利用docker进行分布式部署，和其内部实现的负载均衡，使得每台服务器的性能最大程度上的使用。

------------------------------------------------------------------------------------------------------------------

工作经历

2016/8--2018/10深圳七维科技有限公司
python开发工程师 | 薪资保密 | 研发一部 
  行业类别：计算机软件 |   企业性质：民营公司 |   规模：少于50人
工作内容：负责python web服务开发，公司网站及平台的开发工作
 参与项目讨论，进行需求分析
 完成业务需求开发，完成接口文档编写
 负责代码的调试与优化，代码维护

项目经验

2018/1--2018/8项目名称:海克曼家居
项目职责：1、参与项目需求分析讨论，完成用户模块代码、完成产品模块代码，设计数据表
 2、写用户注册的API接口，利用第三方工具生成图片验证码，短信验证码，发送短信、采用Celery异步提高效率
 3、使用django-corsheaders扩展实现CORS域名跨域请求，为CORS添加白名单解决后端对跨域访问的支持
 4、为防止session认证带来的CSRF攻击，我使用JWT记录用户注册或登录状态，为用户创建身份认证凭证，用Django REST framework JWT扩展来完成向用户签发和核验JWT
 5、用Docker ＋ FastDFS系统来实现图片存储的功能
 6、用CKEditor富文本编辑器，方便录入产品并编辑产品的详细信息
 7、通过DRF框架中过滤，排序，分页，序列化器数据的返回完成产品列表页面的展示
 8、使用页面静态化技术，通过django-crontab执行定时任务，减轻服务器压力，提升访问速度
 9、使用DRF-extensions提供的缓存支持完成热销产品的展示
 10、使用docker ＋ Elasticsearch ＋ haystack全文搜索引擎实现产品搜索的功能
项目描述：海克曼家居是深圳一家帮助客户寻找优质家居设计的公司网站，帮客户以最小的投入，分享最优质的家居资源
 项目用Django REST framework框架开发，用Django的ORM与数据库交互,利用DjangoMVT模式开发，使用Mysql ＋ Redis数据库，以前后端分离的模式实现具体的业务逻辑
2017/5--2017/12项目名称:红荔村美食
项目职责：1.参与项目的需求分析讨论，完成菜品的展示模块
 2.写菜品页面的接口，设计数据表
 3.用FastDFS分布式文件系统实现大容量的文件存储。 FastDFS负责存储，nginx负责读取，以此来提高效率。
 4.采用 CKEditor 富文本编辑器，在页面中快速简单的编辑带格式的文本
 5.为了提升访问速度，应对频繁被访问，使用页面静态化技术提升访问速度
 6.通过DRF框架中过滤，排序，分页，序列化器数据的返回完成菜品列表页面的展示
 7.完成菜品详情页展示
项目描述：红荔村美食是为深圳市红荔村餐饮有限公司打造的一个网上餐饮服务网站
 利用Django REST framework框架，采用前后端分离的方式开发，利用DjangoMVT模式，数据库采用Mysql ＋ Redis相结合的模式
2016/9--2017/3项目名称:兴辉商业资讯
项目职责：参与项目的需求分析，实现业务逻辑，编写新闻详情页模块代码
 完成新闻首页和新闻详情页的基类模板抽取
 使用装饰器去加载用户信息并记录到g变量，直接使用g变量取到用户数据，减少重复的代码
 利用jinja2模板引擎渲染模板返回
 把图片信息等静态文件存放在阿里云对象文件存储系统，降低项目成本
 使用请求钩子对用户的访问数据进行统计
 实现判断用户是否收藏某个新闻的代码
 实现新闻收藏和取消收藏的后端代码
 实现新闻评论的后端代码
 实现新闻点赞的后端代码
项目描述：兴辉商业资讯是一个关于投资，创业，贸易，商业策略，市场分析等的新闻资讯类型的网站，用户可以在这里查看和发布相关新闻
 项目基于python的Flask框架实现，采用前后端不分离的方式，使用Redis ＋ MySQL 进行数据存储

自我评价

熟练掌握python开发，有良好 PEP8编码习惯 熟悉Linux开发，掌握常用的Linux命令 熟练使用Django、flask框架 熟练使用RESTframework，MVT，ORM进行程序开发，熟悉RESTful API 接口风格 熟悉celery进行异步操作，熟悉celery加redis的异步定时任务的处理 熟练面向对象编程，装饰器的使用 熟悉 Mysql，Redis，MongoDB数据库的操作 熟练掌握MySQL的基本增删改查操作，熟悉数据库事务，索引，主从等操作 熟悉uWSGI ＋ Nginx进行项目部署 熟悉UDP、TCP、HTTP网络通讯协议 熟悉多线程，多进程，协程的应用 熟悉正则表达式的使用 熟悉单元测试 熟悉使用源代码管理工具Git 懂前端html/css/js语言 能够阅读开发文档


2016.11--2017.01项目名称:淘宝京东书籍类数据爬取
项目职责：1.分析需求
2.对需求的字段进行规划
3.制作简单的需求文档
4.分析网站的源代码、解析数据存放位置
5.确认爬虫所用的框架和一些用到的相关技术
6.用scrapy框架或者scrapy_redis框架编写爬虫的代码
7.对数据进行简单的去重和筛选
8.对数据存入数据库
项目描述：项目技术：scrapy-redis，浏览器模拟，代理，ssl免验证，re, xpah，selenium＋phantomjs，Redis，mongodb
项目工具：pycharm，xpath插件，
项目过程：
1.	使用scrapy框架的crawlspider来创建爬虫,利用rule规则提取相关链接并调用函数进行解析
2.	最终解析出来的链接,请求他的时候会强制让登陆,所以采用模拟登陆技术
3.	模拟登陆成功之后还会有英文字母的验证码,采用打码平台进行识别
4.	获得数据，数据提取
5.	数据持久化



2017/11--2018/1项目名称:机票爬虫
项目职责：1. 项目采用srapy框架
 2. 使用selenium ＋ phantomjs模拟浏览器行为获取数据
 3. 使用scrapy-redis 进行项目部署和去重，实现分布式
 4. 数据库使用MongoDB的存储
 5. 编写shell 脚本命令
 6. 两个网站的价格都是采用css样式反扒，故计算css偏移量进行价格获取
项目描述：整合了国内两大机票网站（去哪儿＋携程）， 对网站中机票信息（航空公司，飞行时间，价格， 飞机型号等）进行爬取


******************************************************************************************************************
2016.05--2018.05中山市高端科技服务有限公司
python爬虫工程师 | 6001-8000元/月 
  行业类别：互联网/电子商务
工作内容：行业类别：计算机软件
工作描述：
1.负责设计和开发网络爬虫系统,进行多个平台信息的抓取和分析工作。
2.负责网页信息数据的抽取、清洗、消重等工作，提升平台的抓取效率。
3.设计基于Redis的分布式爬虫。
4.优化爬取策略和算法,提升爬虫的爬取效率。
5.负责基于Linux环境下的项目部署,做一些简单的运维工作。
6.项目定期维护与优化。

项目经验

2018.06--2018.11项目名称:安居客租房网爬虫
项目职责：责任描述：
1.根据公司项目需求, 使用scrapy爬虫框架采集安居客网指定的楼盘信息。
2.对网页结构进行分析, 采用xpath解析技术解析网页中的目标数据, 制定相应的数据采集策略。
3.研究安居客反爬虫策略，使用阿布云代理解决限制IP问题。
4.并对数据进行清洗去重操作, 将数据异步写入数据库，增量爬取目标数据。
5.负责部署爬虫项目, 并对项目进行监控, 异常错误发送邮件提示。
6.负责爬虫代码的维护和优化。
项目描述：项目描述：根据公司项目需求，对安居客网租房数据信息进行爬取，主要爬取的字段有：详细地址，户型建筑面积，楼层，租金，地址，装修，朝向，类型，房屋配套等字段。并研究该平台反爬虫策略，制定解决方案。
2018.06--2018.11项目名称:贝壳租房网爬虫项目
项目职责：责任描述：
1.按照公司所提的项目需求，使用scrapy爬虫框架采集目标数据。
2.通过对网页结构进行分析，制定相应的数据采集策略，使用xpath解析技术解析网页数据。
3.通过使用IP池解决贝壳的限制IP问题，通过使用云打码第三方平台解决爬虫爬取过程中所遇到的验证码问题。
4.将采集到的数据进行清洗，去重操作，并异步写入数据库，增量爬取目标数据。
5.负责爬虫项目部署，并实时监控。
6.负责代码的维护和优化
项目描述：项目描述：根据公司项目需求，对安居客网租房数据信息进行爬取，主要爬取的字段有：详细地址，户型建筑面积，楼层，租金，地址，装修，朝向，类型，房屋配套等字段。并研究该平台反爬虫策略，制定解决方案。
2016.06--2018.05项目名称:饿了么外卖爬虫
项目职责：责任描述：
1.根据公司项目需求，使用多个饿了么账号进行饿了么平台外卖数据爬取。
2.研究饿了么平台外卖反爬虫策略，使用 Redis 存储用户 Cookie，维护 Cookie 池可用性。
3.负责将爬取的数据去重，并将数据异步写入数据库。
4.将按照要求提取到的数据保存到 Excel 表格备用。
5.开启定时采集任务，对数据进行增量爬取。
6.编写爬虫异常预警脚本，通过邮件通知相关开发人员。
7.负责代码的维护和优化
项目描述：项目描述：根据公司项目需求，对饿了么平台外卖数据进行爬取，主要爬取的字段有：店铺名称，菜品价格，菜品销量，评分，文描，店铺总营业额，总销量，订单量，满减活动，首单立减，然后根据菜品销量
进行排序取 TOP20，并研究该平台反爬虫策略，制定解决方案
2016.06--2018.05项目名称:饿了么后台爬虫
项目职责：责任描述：
1. 通过客户方提供的饿了么账号，使用多个饿了么账号批量登录饿了么后台并下载对应的财务报表和营
业统计报表。
2.读取财务报表和营业统计报表内容，并将表格内容存入数据库。
3.研究饿了么后台反爬虫策略。
4.通过批量登录饿了么后台后，将获取到的 Cookie 存放到一个列表中，由于每个 cookie 的有效期是一个月，所以也要定期维护 Cookie 池的可用性。
5.负责将爬取的数据去重，并将数据异步写入数据库。
6.负责代码的维护和优化。
项目描述：项目描述：根据公司项目需求，通过公司客户提供的饿了么后台账号，批量登录饿了么后台，编写爬虫程
序，下载每个账号所对应的财务报表和营业统计报表，并研究该平台反爬虫策略，制定解决方案。
2016.06--2018.05项目名称:京东电子产品爬虫
项目职责：责任描述:
1.根据公司项目开发需求,提取京东商城指定电子产品信息。
2.将提取到的数据进行清洗，数据去重，入库操作，并保存为Excel表格备用。
3.结合Redis部署分布式爬虫,充分利用多服务器资源,优化数据采集效率。
4.采用布隆去重策略,保障所有机器采集地址的去重。
5.采用定时开启采集任务的方式，对信息进行增量爬取。
6.进行后期代码的维护和优化。
项目描述：项目描述:根据公司项目需求,对京东电子产品信息进行数据采集,提取指定产品的详细信息，例如：笔记本电脑的卖点,尺寸，特点，存储，硬盘等,并对数据进行清洗和存储。
2016.06--2018.05项目名称:豆瓣电影影评爬虫
项目职责：责任描述： 
1.根据公司项目需求, 采集豆瓣电影中的电影影评信息。
2.分析网页结构特点, 对数据进行搜索查找, 制定相应的数据采集策略。
3.使用xpath解析网页数据, 并对数据进行清洗去重操作, 将数据异步写入数据库。
4.负责部署爬虫项目, 并对项目进行监控, 异常错误发送邮件提示。
5.负责爬虫代码的维护和优化。
项目描述：项目描述: 根据公司项目需求 ,对豆瓣电影中的电影信息进行数据采集, 提取到观众对每部电影的评分、建议、评价内容等，并对提取到的数据进行清洗和存储。



*********************************************************************************************
求职状态：目前正在找工作

期望地点：上海

期望职位：软件工程师

工作性质：全职

期望行业：计算机软件

期望薪资：8000-9999元/月

到岗时间：随时

简历详情一眼看穿ta(Beta测试版)

教育经历

2012/9--2016/7河南理工大学万方科技学院本科计算机网络

工作经历

2016/12--至今北京下厨房科技有限公司
Python开发工程师 | 薪资保密 | 开发部 
  行业类别：计算机软件 |   企业性质：民营公司 |   规模：50-150人
工作内容：1.设计爬虫代码的整体思路，选择urllib2库自己编写爬虫框架或者使用scraapy-redis框架分析各种网站形态，发现它们的特点和规律，通过xpath等方式抓取数据爬虫代码。以及后期对爬虫代码的维护，修改及优化。负责爬取数据的解析入库，以及对数据的简单优化。
 2.设计web后端功能实现算法，对用户模块功能进行完善进行。连mysql，实现对用户信息的存储，实现多表查询，添加后台xadmin管理模块，实现对用的管理功能。
2016/1--2016/12友进城
web后端工程师 | 薪资保密 | 开发部 
  行业类别：计算机软件 |   企业性质：民营公司 |   规模：少于50人
工作内容：以python语法为基础，利用Django框架技术实现前段页面与后端的连接，实现前端功能。使前端，后台，和数据库实现整体的完善，使之成功运营。

项目经验

2018/8--至今项目名称:美团店铺信息抓取
项目职责：在本项目中本人主要是作为Leader的角色统筹整个项目。
 1.分析页面，设计爬虫思路，首先需要获取json接口； 
 2.确定入口链接->具体抓取的页面链接->确定需要采集的字段->
 入库：mysql；
 3.通过打码平台解决验证问题，使用ip代理进行解决反爬 
 4.使用resqusts, pymysql等类库作为基础开发编程； 
 5.使用css，xpath，re等对数据进行抽取和清洗；
 6.将获取的信息存入库中
项目描述：爬取美团美食分类店铺信息，包括店铺的销量，所售商品的种类，用户的评分和评价等
2018/1--2018/7项目名称:美食杰，天天美食等网站的抓取和分析
项目职责：我的职责有以下几点：
 1.使用Scrapy-Redis分布式框架爬取目标网站
 2.使用Selenium和Chrome-headless抓取js动态数据
 3.设置User-Agent池、IP代理，防止被封
 4. 使用Xpath（lxml）进行页面分析并提取数据 
 5. 使用redis进行数据存储
 6. 使用Pandas进进行清洗并生成Excel报表 
 7. 使用Jupyter notebook工具，matplotlib制作可视化数据
 分析报告
项目描述：抓取马蜂窝，携程等高评分景点攻略和热门游记，景点游玩的季节时间，景点的著名区域的具体信息和门票价格开放时间等
2017/9--2017/12项目名称:下厨房网站重构
项目职责：1. 使用Django技术搭建一个框架，实现前后端结合。
 2.使用mysql进行数据存储，并对数据进行优化。
 3.使用xmdmin进行后台管理，和权限的修改
 4.使用git进行对主分支的推送，实现项目的整合。
项目描述：由于原始网站过于简单，对网站进行重开发。1.用户模块，对用户信息信息进行补充，作品展示，我的菜单等。2.信息推送模块，用户提交信息模块，3.后台管理模块，修改不同用户的权限等
2017/6--2017/8项目名称:菜谱信息抓取
项目职责：我的职责有以下几点：
 1.分析页面，设计爬虫思路，运用scrapy框架首先需要获取start_urls获取第一批URL请求； 
 2.请求由引擎交给调度器入请求队列，交给下载器获取对应的响应资源
 3.提取出新的url获取新的URL信息用xpath获取请求资源对数据进行抽取和清洗
 4.将获取的信息存入mysql数据库
项目描述：通过抓取美食菜谱，中国菜谱网，美食天下等网站各种美食的制作方式和配料信息等
2016/1--2016/11项目名称:友进城
项目职责：作为开发者和团队一起开发整个项目，负责部分模块的构建，
 1.用户模块：连接MySQL数据库实现对用户信息的增删改等操作。
 2.优惠券模块：实现门店添加设置优惠券。用户在消费的时候把用户 信息绑定优惠劵。
 3.商品模块：对mysql数据进行查询，读取其中商品数据并通过Django 把数据展示在HTML页面中
 4.添加购物车，查询购物车，修改购物车，删除购物车，登录时合并 购物车5大逻辑实现
 5. 后台管理模块：通过admin模块对用户的信息进行修改或解除系统 
 误判而对用户信息的锁定。
 6.维护系统的正常运行
项目描述：运用Python的Django框架构建完善友进城电子商城，使之实现运行，

自我评价

本人性格热情开朗，待人友好，为人真诚谦虚。为人诚恳、脚踏实地，有较强的团队精神，工作积极进取，态度认真。 所会的技术: 1.爬虫框架scrapy和scrapy-redis分布式爬虫 2. Python Web后端django框架等 3.使用关系型MySQL和非关系型redis进行数据的持久化 4.Urllib2、Requests模块获取数据，运用Selenium获取数据 5.运用Jupyter开发环境使用pandas对数据进行挖掘和分析 6.熟练运用正则表达式、BeautifulSoup、Lxml解析数据 7.Python基础编程,html,css,javascript等 8.linux或者Windows环境和版本管理工具git 一. 熟练运用scrapy框架和redis分布爬虫，能够很好的规避各种反爬虫机制比如基于用户的反爬虫可以通过ip代理等。二. 在Python web后端，利用Django框架进行web后台功能的完善。实现web前端，后端与数据库的交互。 三。本人有较强的团队精神，有良好的代码习惯和代码风格。